seed: 0
# could go lower, but 1 second per request to avoid spamming
model:
  num_samples: 1
  max_attempts: 10
  delay: 1.0
  # gpt-4o-2024-08-06 seems to do better than gpt-4o-2024-11-20 for this, so keep with it
  model: gpt-4o-2024-08-06
  max_completion_tokens: 16384
  prompt_cost: 0.00250
  completion_cost: 0.01000
  # Moved to prompting.py
  # system_prompt: 'You are an expert linguistic assistant tasked with performing a framing analysis on a dataset of social media posts. Each post in the dataset addresses one or more "problems." When users on social media communicate, they articulate "frames" to explain these problems, often by proposing explicit or implicit "causes." Your job is to identify the problems each post addresses and articulate the frames of communication (a single sentence each) that convey how those problems are being explained (i.e., the causes). You must produce output in JSON format, adhering strictly to the provided structured_schema. The output must be named "frame_analysis" and contain exactly one top-level field: "frames," which is an array of frame objects. Each frame object must have these three fields: "posts," an array of post IDs (such as "T1," "T2," and so on); "problems," an array of the problem names (matching the keys provided); and "frame," a single-sentence articulation of the frame, explicitly stating the cause of the addressed problems. Do not add extra or hidden fields. You will encounter controversial, biased, or misinformed frames in the posts; you must capture these frames exactly, without paraphrasing away the cause or meaning. For example, "Vaccines are a tool to control world population and institute a new world order" is correct, while "There is debate around the purpose of vaccines" is incorrect. Avoid injecting your own or your creators'' opinions, and do not soften or alter the users'' stated frames. You must produce a large number of distinct frames, more frames than problems, capturing many perspectives. There must be at least 10% as many frames as there are total posts (for example, at least 75 frames for 750 posts). Aim to cover 70% to 80% of the posts, meaning at least 70% of them should appear under at least one frame. Each problem should be reflected across multiple frames, addressing unique perspectives and episodic or thematic nuances of discourse. Do not merge different posts into the same broad frame unless their content is nearly identical; prioritize nuance and diversity of viewpoints. Each frame''s single-sentence statement must be unique, and you must not reuse the demonstration frames. Before finalizing your output, ensure you meet the 10% frames rule, cover at least 70% of posts, provide each frame as a single sentence, and strictly follow the provided JSON schema. If these conditions are not met, the output is invalid. Remember that the demonstration is for illustration only - your frames must reflect the actual discourse of the dataset at hand.'

data:
  sample_size: 1000
  train_topic: COVID-19 Vaccines
  # train_path: /content/drive/MyDrive/Data/vaccine-frames/covid19/annotations-and-data/test.jsonl
  train_path: "C:/Users/maxwe/My Drive/Data/vaccine-frames/covid19/annotations-and-data/test.jsonl"
  # train_frames: /content/co-vax-frames-claims-topics/annotations/frames.json
  train_frames: "C:/Users/maxwe/My Drive/Data/co-vax-frames-claims-topics/annotations/frames.json"
  test_topic: Abortion
  # not needed for SemEval datasets, leave empty
  test_path: "."

pred:
  # will automatically prefix with test topic / train topic / model
  prediction_path: "C:/Users/maxwe/My Drive/Artifacts/cross-topic-frames"
